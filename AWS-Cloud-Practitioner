Udemy: [NEW] Ultimate AWS Certified Cloud Practitioner CLF-C02 2025

Free account - For 1 year

Cloud computing: Ondemand delivery of computing Services Eg: Computers, Databases, applications and other IT resources
Cloud Deployment models: Private,Public and Hybrid(public + Private (company owned infrastucture))
Types of cloud computing: 
1) IAAS (Infrastructure as a Code)
    -Getting networking, Computers, Data storage space from cloud
2) PAAS (Platform as a service)
    -Deploying our applications on cloud 
3) SAAS (Software as a service)
    -Getting softwares from cloud they are managed by cloud. example version upgrades etc

Region: Is a Location that has one or more availaility Zones.
     -In a Region we have 3 to 6 availaility Zones.
Availability Zones: Is a collection of one or more discrete data centres.
     -They are separated from each other so that are isolated from disaster
Now we can say Region is a collection of cluster of datacentres

AWS edge locations: are data centers positioned close to users that cache copies of your content 
and run parts of your applications for faster delivery, improved performance, and lower latency. 

*)IAM : Identity Access Management
----------------------------------
Its a global service
Root user is created by default shouldn't be used or shared
Users - people in the organization can be grouped
Group - only contain users not other groups

Users can belong to multiple groups, Users can also be not part of any groups

Policy: Its a json document to provide permissions to Users or groups to access aws services 
SC: IAM Policy is assigned to Users or Groups to provide permissions
Eg: admin, IAMReadonlyaccess

IAM Role: will provide permissions to AWS resources to access other resources in aws or to perform tasks in this aws account or other aws accounts.
Eg: Ec2Instance roles, LambdaFunction Roles
SC: Policy provide permissions for users, IAM Role provides permissions to AWS Services/resources to do any task in aws

S3 bucket policy: To allow a s3 bucket to be able to access by public then we will add S3 bucket policy to it.

Number of ways to access AWS
1) AWS Management console : Using Web browser You can access all the resource of AWS here.
2) AWS CLI: Using Access Keys
3) AWS SDK: to access api's in the application code. accessed by AccessK Keys

*)EC2: Elastic Cloud Compute
-Its a computer (linux,Windows,Mac)
-t2.micro is an image with 1VCPU, 1GB RAM, 
-Bootstrapping scripts or Ec2 User Data Scripts - A script used to install softwares, do any tasks at the time of Ec2 creation. This script run only once at the time of creation.
-You can start /Stop/Terminate resources to less the cost
-EBS : Its like Hard Disk (Elastic Block Storage)

Ports:
------
22 - SSH - login to linux machine
21- FTP -Upload files to file share
22 - SFTP (Secure File Transfer Protocol) - Upload files using SSH
80 - HTTP -Access unsecured Websites
443 - HTTPS - access Secured websites
3389 - RDP (Remote Desktop Protocol) -Login to windows instances
1433 - sql port


*)Security Groups: 
-Controls how traffic is allowed into or out of AWS resources
-Acts like Firewall
-They only contain allow rules
-Rules can be referenced by IP or security Group
-Region specific. If you change the region then this security group wont be available there.

AWS services
-------------
*)Ec2: Elastic cloud Computing : like our computers

*)EBS: Elastic block storage : we will attach storage to the Ec2. They are network drives.like D drive storage,E drive storage
- EBS volumes are bound to availability zones. you cannot attach an ebs of us-east to us-west.where Ec2 is in us-east
- We can detatch and attach to another instance very quickly
Snapshot is a copy of an Amazon EBS (Elastic Block Storage) volume.
AMI: Amazon Machine Image
Amazon produces few AMI's : public AMI
we can also create our own AMI and do our own customization of Ec2 instance. own OS, software, configuration, monitoring etc
AWS Market place AMI: Some body created it and sells at market place

*) Ec2 Image Builder: Using this we can create image of Ec2 instance and add softwares to it and we can test it and create 100s of Ec2 instance

*) EFS: Elastic File system
Its Managed Network file system.
Can be mounted to 100's of LINUX instances
Can be in any Avaliability Zones
Limited to only Linux instances

*) Fsx 
3rd party high performace computing

Scalability: Adding resources to the application/system to handle the Load
Types: 
Vertical Scalbilty: Increasing the size of the resource (Example increase the size of database, increase t2.micro to t2.large instance)
 -Scale up : Increase the size
 -Scale down: Decrease the size
Horizontal Scalability: Increasing no of resources ()
 -Scale out: Increase the resources
 -Scale in: Decrease the resources

High Availabilty: Running your application /system in at least 2 availability Zones. 
Our application will be available if one datacentre goes down or at any disaster

*)Load Balancer: distributes loads to ultiple servers equally.
4 types of Load balancer
1) Application Load balancer (Http,HTTPS only) - Layer 7
users -->ALB--> (Application on multiple servers)
2) Network Load balancer (Ultra high performance, allows for TCP ) -Layer 4
users -->NLB--> (Application on multiple servers) -- This is basically used when we need high performance when there is a need of transfer millions of transactions per second in an application
3) Gateway Load balancer - Layer 3
users -->GWLB--> (security security cheeck app) --> (Application on multiple servers)  --This is used where there is aneed for high security
4) Classic Load balancer (Retired in 2023)

SC to create Application Load balancer
Create your Ec2 instances
Create Load balancer -- create a target group and add Ec2 instances to target group while creating Load balancer. Thats it.
You can point DNs to this Load balancer

Auto Scaling Group: We can increase or decrease the instances based on the load
----------------
Create an autoscaling group define minimum and max capacity and attach the load balancer created in previous step. thats it
Scaling strategies:
a) Manual Scaling: Update the min and max capacity manuallyu
b) Dynamic scaling:
    -Simple: when cloud watch alarm is triggered (example CPU>70%) then add 2 instances
    -Target tracking scaling: I want the average ASG CPU to stay at around 40%
    -Scheduled Scaling : Increase capacity to 10- on friday at 5pm

c) Predictive scaling: Uses machine learning and predicts futre a head and increases or decreases the instances

*) S3: Simple Storage Service
USed to store the data(files, backups any data) in the S3 buckets
Buckets are like directories
Buckets are defined at region level

Naming convention of bucket:
• No uppercase, No underscore
• 3-63 characters long
• Not an IP
• Must start with lowercase letter or number
• Must NOT start with the prefix xn--
• Must NOT end with the suffix -s3alias

what ever we are storing they are referreed as objects
Max object size is 5TB
If an object is greater than 5 GB then it should be uploaded as multipart. it should be upload as 1000 parts of 5GB.

S3 bucket policy: To allow a s3 bucket to be able to access by public then we will add S3 bucket policy to it.
We can host static website in S3 and use it with that S3 url as website url

• Buckets vs Objects: global unique name, tied to a region
• S3 security: IAM policy, S3 Bucket Policy (public access), S3 Encryption
• S3 Websites: host a static website on Amazon S3
• S3 Versioning: multiple versions for files, prevent accidental deletes
• S3 Replication: same-region or cross-region, must enable versioning
• S3 Storage Classes: Standard, IA, 1Z-IA, Intelligent, Glacier (Instant, Flexible, Deep)
• Snowball: import data onto S3 through a physical device, edge computing
• Storage Gateway: hybrid solution to extend on-premises storage to S3

Databases & Analytics Summary in AWS
• Relational Databases - OLTP: RDS & Aurora (SQL)
• Differences between Multi-AZ, Read Replicas, Multi-Region
• In-memory Database: ElastiCache
• Key/Value Database: DynamoDB (serverless) & DAX (cache for DynamoDB)
• Warehouse - OLAP: Redshift (SQL)
• Hadoop Cluster: EMR
• Athena: query data on Amazon S3 (serverless & SQL)
• QuickSight: dashboards on your data (serverless)
• DocumentDB: “Aurora for MongoDB” (JSON – NoSQL database)
• Amazon Managed Blockchain: managed Hyperledger Fabric & Ethereum blockchains
• Glue: Managed ETL (Extract Transform Load) and Data Catalog service
• Database Migration: DMS
• Neptune: graph database
• Timestream: time-series database

Docker: is a containerization technology
• Docker is a software development platform to deploy apps
• Apps are packaged in containers that can be run on any OS
• Apps run the same, regardless of where they’re run 
• Any machine
• No compatibility issues
• Predictable behavior
• Less work
• Easier to maintain and deploy
• Works with any language, any OS, any technology
• Scale containers up and down very quickly (seconds

*)ECS 
------
• ECS = Elastic Container Service
• Launch Docker containers on AWS
• You must provision & maintain the infrastructure (the EC2 instances)
• AWS takes care of starting / stopping containers
• Has integrations with the Application Load Balancer

*)Fargate
---------
• Launch Docker containers on AWS
• You do not provision the infrastructure (no EC2 instances to manage) – simpler!
• Serverless offering • AWS just runs containers for you based on the CPU / RAM you need

*) ECR 
-------
• Elastic Container Registry • Private Docker Registry on AWS
• This is where you store your Docker images so they can be run by ECS or Fargate

*)Amazon EKS
------------
• EKS = Elastic Kubernetes Service
• Allows you to launch managed Kubernetes clusters on AWS
• Kubernetes is an open-source system for management, deployment
• Scaling of containerized apps (Docker)
• Containers can be hosted on:
• EC2 instances
• Fargate (Serverless)
• Kubernetes is cloud-agnostic (can be used in any cloud – Azure, GCP…)

What’s serverless?
• Serverless is a new paradigm in which the developers don’t have to manage servers anymore…
• They just deploy code
• They just deploy… functions !
• Initially... Serverless == FaaS (Function as a Service)
• Serverless was pioneered by AWS Lambda but now also includes anything that’s managed: “databases, messaging, storage, etc.”
• Serverless does not mean there are no servers…it means you just don’t manage / provision / see them

AWS Lambda
• Virtual functions – no servers to manage!
• Limited by time - short executions for 15 minutes
• Run on-demand
• Scaling is automated! 

EC2
• Virtual Servers in the Cloud
• Limited by RAM and CPU
• Continuously running
• Scaling means intervention to add / remove servers

Benefits of AWS Lambda
• Easy Pricing:
• Pay per request and compute time
• Free tier of 1,000,000 AWS Lambda requests and 400,000 GBs of compute time
• Integrated with the whole AWS suite of services
• Event-Driven: functions get invoked by AWS when needed
• Integrated with many programming languages
• Easy monitoring through AWS CloudWatch
• Easy to get more resources per functions (up to 10GB of RAM!)
• Increasing RAM will also improve CPU and network!

AWS Lambda Pricing: example • You can find overall pricing information here:
https://aws.amazon.com/lambda/pricing/
• Pay per calls:
• First 1,000,000 requests are free • $0.20 per 1 million requests thereafter ($0.0000002 per request)
• Pay per duration: (in increment of 1 ms)
• 400,000 GB -seconds of compute time per month for FREE
• == 400,000 seconds if function is 1GB RAM 
• == 3,200,000 seconds if function is 128 MB RAM • After that $1.00 for 600,000 GB-seconds
• It is usually very cheap to run AWS Lambda so it’s very popular

Amazon API Gateway
• Example: building a serverless API
• Fully managed service for developers to easily create, publish, maintain, monitor, and secure APIs
• Serverless and scalable
• Supports RESTful APIs and WebSocket APIs
• Support for security, user authentication, API throttling, API keys, monitoring... 

AWS Batch
• A “batch” job is a job with a start and an end runs more than 15 minutes uses Ec2 instances or spot instances
• Fully managed batch processing at any scale
• Efficiently run 100,000s of computing batch jobs on AWS
• Batch will dynamically launch EC2 instances or Spot Instances
• AWS Batch provisions the right amount of compute / memory
• You submit or schedule batch jobs and AWS Batch does the rest!
• Batch jobs are defined as Docker images and run on ECS
• Helpful for cost optimizations and focusing less on the infrastructure

Batch vs Lambda 
* Lambda: 
• Time limit - 15 minutes , Lambda function is set to run at most 15 minutes if it more than that you need to go for Batch jobs
• Limited runtimes 
• Limited temporary disk space • Serverless 

* Batch: 
• No time limit • Any runtime as long as it’s packaged as a Docker image 
• Rely on EBS / instance store for disk space • Relies on EC2 (can be managed by AWS)

*)LightSail:
for new begginers who want to use aws cloud with limited knowledge they can use Light sail
Here they can order Ec2, DB,networking,configuration in simple way just by selecting thats it they can host websites. but this cannot handle all features.

*) CloudFormation: You can create infrastructure using Code.
It uses yaml code
We need to upload this yaml template in aws to create , update resources.

*)AWS CDK : AWS Cloud Development kit
You can create infrastructure using CDK  in AWS
you can use java script, typescript,python,java and dotnet
this code is compiled into cloudformation template either to Json or yaml format

*) Bean stalk:
Use to deploy your applications
Its PAAS service
It will automaticaaly create autoscaling group, Load balancer, Url, based on the configuration we select on AWS while creating it. We can also point the app to DB.
It supports only cloud

AWS CodeDeploy
• We want to deploy our application automatically
• Works with EC2 Instances
• Works with On-Premises Servers
• Hybrid service 
• Servers / Instances must be provisioned and configured ahead of time with the CodeDeploy Agent

Deployment - Summary
*) CloudFormation: (AWS only)
• Infrastructure as Code, works with almost all of AWS resources

*) Beanstalk: (AWS only)
• Platform as a Service (PaaS), limited to certain programming languages or Docker
• Deploy code consistently with a known architecture: ex, ALB + EC2 + RDS 
*)CodeDeploy (hybrid): deploy & upgrade any application onto servers
*)Systems Manager (hybrid): patch, configure and run commands at scale

Developer Services - Summary
• CodeCommit: Store code in private git repository (version controlled)
• CodeBuild: Build & test code in AWS 
• CodeDeploy: Deploy code onto servers
• CodePipeline: Orchestration of pipeline (from code to build to deploy)
• CodeArtifact: Store software packages / dependencies on AWS
• AWS CDK: Define your cloud infrastructure using a programming language


Global Applications in AWS
• Global DNS: Route 53
    • Great to route users to the closest deployment with least latency
    • Great for disaster recovery strategies
• Global Content Delivery Network (CDN): CloudFront
    • Replicate part of your application to AWS Edge Locations – decrease latency
    • Cache common requests – improved user experience and decreased latency
• S3 Transfer Acceleration
    • Accelerate global uploads & downloads into Amazon S3
• AWS Global Accelerator:
    • Improve global application availability and performance using the AWS global network

Amazon Route 53 Overview
• Route53 is a Managed DNS (Domain Name System) service- Same like Go daddy we can purchase Domain names and use it
    • DNS is a collection of rules and records which helps clients understand
how to reach a server through URLs.
• In AWS, the most common records are:
    • www.google.com => 12.34.56.78 == A record (IPv4)
    • www.google.com => 2001:0db8:85a3:0000:0000:8a2e:0370:7334 == AAAA IPv6
    • search.google.com => www.google.com == CNAME: hostname to hostname
    • example.com => AWS resource == Alias (ex: ELB, CloudFront, S3, RDS, etc…)

Amazon CloudFront: Amazon CloudFront is a content delivery network (CDN) service 
that uses a globally distributed network of edge locations to deliver data, videos, applications, and APIs to users with low latency and high transfer speeds
    • Content Delivery Network (CDN)
    • Improves read performance, content is cached at the edge Locations
    • Improves users experience
    • Hundreds of Points of Presence globally (edge locations, caches)
    • DDoS protection (because worldwide), integration with Shield, AWS Web Application Firewall

We can use CDN for S3
If we have a S3 bucket we can add CDN to it so that the S3 bucket content is cached in edge locations
and the files are retreived very fast from S3 as the cache is available in Edge locations


S3 Transfer Acceleration: Its a aws service which uses Globa network
• Increase transfer speed by transferring file to an AWS edge location
which will forward the data to the S3 bucket in the target region

AWS Global Accelerator : this is AWS global networking service
This is used for your applications 
• Improve global application availability and performance using the AWS global network
• Leverage the AWS internal network to optimize the route to your application (60% improvement)
• 2 Anycast IP are created for your application and traffic is sent through Edge Locations
• The Edge locations send the traffic to your application

AWS Outposts:
AWS will get the server racks and place it in our onpremises to create Ec2, Ebs kind of services on premises

AWS Wavelengths:
Deploying AWS services at the nearest 5g networks

AWS Local Zones:
Zones that are closest to end users to avoid delay
Aws provides some default Local zones or we can create our own Local zones.


